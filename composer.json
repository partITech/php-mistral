{
    "name": "partitech/php-mistral",
    "description": "Connect to MistralAi inference or to Llama.cpp",
    "license": "MIT",
    "autoload": {
        "psr-4": {
            "Partitech\\PhpMistral\\": "src"
        }
    },
    "require-dev": {
        "phpunit/phpunit": "^9.5",
        "symfony/http-client": "^7.2",
        "guzzlehttp/guzzle": "^7.9",
        "php-http/curl-client": "^2.3",
        "php-http/message": "^1.16",
        "ext-curl": "*"
    },
    "scripts": {
        "test": "phpunit"
    },
    "require": {
        "php": ">=8.3",
        "ext-fileinfo": "*",
        "ext-http": "*",
        "symfony/mime": "^7.2",
        "ramsey/uuid": "^4.7",
        "knplabs/php-json-schema": "^0.1.0",
        "psr/http-client-implementation": "*",
        "psr/http-factory-implementation": "*",
        "php-http/discovery": "^1.20",
        "psr/http-client": "^1.0",
        "nyholm/psr7": "^1.8",
        "php-http/multipart-stream-builder": "^1.4"
    },
    "config": {
        "allow-plugins": {
            "php-http/discovery": true
        }
    }
}
